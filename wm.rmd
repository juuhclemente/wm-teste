---
title: "WM"
author: "Juliana Clemente"
date: "5 de julho de 2018"
output: html_document
---

Passos:
1 - entender os dados!
2 - pre-processing
3 - analise exploratoria
4 - desenv modelo (separar base de teste)
5 - teste do modelo
6 - desenvolver pdf e apresentacao
7 - desenvolver codigo em python do modelo
  - isso pode ser util: https://medium.com/@davidsb/data-science-for-developers-you-have-a-predictive-model-now-what-expose-and-consume-an-r-model-710c3db85a24
8 - subir no github
    

# Metodologia CRISP-DM:

- Entender o Negocio: 
O objetivo do projeto eh identificar qual o perfil das revendas que mais aceitam leads (quantidade de leads aprovados), ja que sao os leads aprovados que geram receita  webmotors.

- Entender os Dados: recolhimento de dados e inicio de atividades para
familiarizacao com os dados, identificando problemas ou conjuntos interessantes.
  - Chaves: ID, SAFRA e PRODUTO 
  - Campos desconhecidos: 
    - Valor_3: numero de leads recusados
    - Valor_2: numero de leads aprovados
    - Valor_1: numero de leads recebidos

- Preparacao dos Dados: construcao do conjunto de dados final a partir
dos dados iniciais. Normalmente ocorre varias vezes no processo.
  - criacao de variaveis

- Modelagem: varias tecnicas de modelagem sao aplicadas, e seus parametros calibrados para otimizacao. A


- Avaliacao: E construido um modelo que parece ter grande qualidade
de uma perspectiva de analise de dados. No entanto, e necessario verificar se o modelo atinge os objetivos do negocio.

- Implantacao: o conhecimento adquirido pelo modelo e organizado e apresentado de uma maneira que o cliente possa utilizar.

# Carregando os dados

```{r "setup", include=FALSE}
path = "C:/Users/sb042583/Documents/Pessoal/Cursos/WM/"
knitr::opts_knit$set(root.dir = path)
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include = FALSE}
list.of.packages <- c("RPostgreSQL", "dplyr", "ggplot2", "caret", "GGally",
                      "rpart")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

#library(openxlsx)
library(RPostgreSQL)
library(dplyr)
library(ggplot2)
library(caret)
library(GGally)
library(rpart)
#library(rpart.plot)
#library(Epi)
library(evtree)
```

Importa os dados com conexão via Postgres

```{r}
# df_client_leads <- read.xlsx(paste0(path, "DadosMin.xlsx")) # importa o arquivo "dados" direto do xlsx

drv <- dbDriver("PostgreSQL")

# cria conexao com a base de dados postgres
con <- dbConnect(drv, dbname = "dadoswm",
                 host = "localhost", port = 5432,
                 user = "postgres", password = "")

#verifica se a tabela existe
dbExistsTable(con, "client_leads")
# TRUE

df_client_leads <- dbGetQuery(con, "SELECT * FROM client_leads")
```

# Exploracao e preparacao dos dados

Altera formato dos dados e corrige missing values
```{r}
#summary(df_client_leads)

df_client_leads <- df_client_leads %>%
  mutate(id_cliente = as.character(id_cliente),
         data = as.factor(data),
         cidade = as.factor(cidade),
         uf = as.factor(uf),
         produto = as.factor(produto),
         marca_de_anuncio_de_blindados = as.factor(marca_de_anuncio_de_blindados),
         # substitui missing value por 0 para leads aprovados e reprovados
         quantidade_de_leads_aprovados = ifelse(is.na(quantidade_de_leads_aprovados), 0,
                                                quantidade_de_leads_aprovados),
         quantidade_de_leads_recusados = ifelse(is.na(quantidade_de_leads_recusados), 0,
                                                quantidade_de_leads_recusados),
         quantidade_de_aceleradores = ifelse(is.na(quantidade_de_aceleradores), 0, 
                                             quantidade_de_aceleradores)) 

summary(df_client_leads)
```

Cria variaveis a partir dos dados
```{r}
df_client_leads <- df_client_leads %>%
  mutate(leads_recebidos = quantidade_de_leads_aprovados + quantidade_de_leads_recusados,
         perc_aprov = quantidade_de_leads_aprovados/ leads_recebidos,
         perc_aprov = ifelse(is.na(perc_aprov), 0, perc_aprov),
         class_aprov = ifelse(perc_aprov > 0.5, 1, 0),
         prop_1 = ifelse(is.na(valor_1/leads_recebidos), 0, valor_1/leads_recebidos),
         prop_2 = ifelse(is.na(valor_2/quantidade_de_leads_aprovados), 0,
                         valor_2/quantidade_de_leads_aprovados),
         prop_3 = ifelse(is.na(valor_3/quantidade_de_leads_recusados), 0, 
                         valor_3/quantidade_de_leads_recusados))
```

Separa os dados em dados em duas partes, uma para treinar e outra para testar o modelo
```{r}
set.seed(1010) #define a semente para fins de reprodutibilidade
train<-createDataPartition(df_client_leads$perc_aprov,p=0.7,list=FALSE)
train_client_leads <-df_client_leads[train,]
test_client_leads  <-df_client_leads[-train,]
```

# Visualizacao dos dados

Boxplot das variáveis numéricas
```{r}
temp <- sapply(train_client_leads, is.numeric)

par(mfrow=c(2,4))
for(i in 1:length(temp)) {
  if(temp[i] == T)
    boxplot(train_client_leads[,i], main=names(train_client_leads)[i])
}
```

Verifica a correlação entre as variaveis numericas
```{r}
library(corrplot)
cor <- cor(train_client_leads[, c(temp)],method="pearson")

#ggcorr(train_client_leads, label = T)
corrplot(cor, method="circle")
```



```{r}
ggplot(data = train_client_leads, mapping = aes(x = quantidade_de_leads_aprovados, y = valor_1)) + geom_jitter()

ggplot(data = train_client_leads, mapping = aes(x = perc_aprov, y = valor_3)) + geom_jitter(aes(colour = perc_aprov))

ggplot(data = student_data, mapping = aes(x = performance, y = nursery)) + geom_jitter(aes(colour = performance))
```





Elimina colunas desnecessarias
```{r}
#busca colunas com variancia perto de 0
#nzv <- nearZeroVar(train_client_leads, saveMetrics = T)
nzv <- nearZeroVar(train_client_leads)

#elimina a coluna "amostra" e "quantidade de aceleradores"
cols_eliminar <- colnames(train_client_leads)[nzv] 
#elimina as colunas valor_1, valor_2 e valor_3, que j? se encontram representadas por prop_1, prop_2 e prop_3
cols_eliminar <- c(cols_eliminar, "valor_1", "valor_2", "valor_3")
#elimina as colunas que representam minimo e maximo de valores (fotos, valor de anuncio e quilometragem), para considerar o valor medio dos itens
cols_eliminar <- c(cols_eliminar, "quantidade_minima_de_fotos", "quantidade_m?xima_de_fotos", 
                   "menor_quilometragem_anunciada", "maior_quilometragem_anunciada", 
                   "menor_valor_de_anuncio", "maior_valor_de_anuncio")

#elimina a coluna "cidade" por ser muito pulverizada
cols_eliminar <- c(cols_eliminar, "cidade")

#elimina as colunas "quantidade de leads aprovados" e "quantidade de leads recusados", para utilizar no lugar "leads recebidos" e "perc_aprov"
cols_eliminar <- c(cols_eliminar, "quantidade_de_leads_aprovados", "quantidade_de_leads_recusados")

train_client_leads <- train_client_leads[, !names(train_client_leads) %in% cols_eliminar]

# cor <- as.data.frame(cor(train_client_leads[, 7:17],method="pearson"))
# ggcorr(train_client_leads, label = T)

#prop_1 tem alta correla??o com  prop_2 e prop_3, vamos manter somente prop_1
cols_eliminar <- c("prop_2", "prop_3")


train_client_leads <- train_client_leads[, !names(train_client_leads) %in% cols_eliminar]

```

# Arvore de decisao
```{r}
model <- ctree(perc_aprov ~ valor_de_anuncio_medio + produto, train_client_leads)
plot(model, type = "simple")

model <- ctree(perc_aprov ~ prop_1 + uf, train_client_leads)
plot(model, type = "simple")

```


# Analise exploratoria dos dados

```{r}
ggplot(data = train_client_leads, mapping = aes(x = quantidade_de_leads_aprovados, y = valor_1)) + geom_jitter()

ggplot(data = train_client_leads, mapping = aes(x = perc_aprov, y = valor_3)) + geom_jitter(aes(colour = perc_aprov))

ggplot(data = student_data, mapping = aes(x = performance, y = nursery)) + geom_jitter(aes(colour = performance))
```

# Desenvolvimento do modelo

```{r}
mod <- lm(perc_aprov ~ ., train_client_leads)
mod$xlevels[["uf"]] <- union(mod$xlevels[["uf"]], levels(test_client_leads$uf))
mod$xlevels[["cidade"]] <- union(mod$xlevels[["cidade"]], levels(test_client_leads$cidade))

pred <- predict(mod, test_client_leads, response = T)
plot(pred - test_client_leads$perc_aprov)

mod <- rpart(perc_aprov ~ ., train_client_leads)
mod$xlevels[["uf"]] <- union(mod$xlevels[["uf"]], levels(test_client_leads$uf))

pred <- predict(mod, test_client_leads, response = T)
plot(pred - test_client_leads$perc_aprov)

summary(mod)
#error <- test_client_leads$perc_aprov - pred
#rmse <- error^2
```



Binomial Logistic Regression

Considerar GLM e Beta distribution!( I interpret the question as being about the ratio of two, positive, real values. If so, (and they are distributed as Gammas) that is a Beta distribution. However, if a is a count of 'successes' out of a known total, b, of 'trials', then this would be a count proportion a/b, not a continuous proportion, and you should use binomial GLM (e.g., logistic regression). For how to do it in R, see e.g. How to do logistic regression in R when outcome is fractional (a ratio of two counts))

Aparentemente, interessante:
https://stats.stackexchange.com/questions/26762/how-to-do-logistic-regression-in-r-when-outcome-is-fractional-a-ratio-of-two-co





# Analises intemediarias

Busca entender o significado dos campos valor_1, valor_2 e valor_3
```{r}
#2437 recusou 0 -> conectado c/ valor_3
#2060 aprovou 0 -> conectado c/ valor_2
#425 não recebeu leads -> conectado c/ valor_1
temp <- df_client_leads %>%
  mutate(temp_1 = valor_1/(quantidade_de_leads_recusados + quantidade_de_leads_aprovados),
         temp_2 = valor_2/quantidade_de_leads_aprovados,
         temp_3 = valor_3/quantidade_de_leads_recusados) %>%
  select(quantidade_de_leads_recusados, quantidade_de_leads_aprovados, 
         valor_1, temp_1, valor_2, temp_2, valor_3, temp_3 ) 

temp <- df_client_leads %>%
    filter(valor_2 == 0)
```


